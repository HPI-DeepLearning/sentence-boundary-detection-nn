net: "net.prototxt"

# Test before training?
test_initialization: true
# Test every nth iteration
test_interval: 200
# How many iterations per test
test_iter: 1

# Base learning rate
base_lr: 0.0001
# Policy for changing the learning rate - multiply by gamma every stepsize iterations
lr_policy: "step"
gamma: 0.1
stepsize: 300000
momentum: 0.9
# Regularization parameter for the weights
weight_decay: 0.0005

# Display training loss every nth iteration
display: 200
# After how many iterations to stop
max_iter: 125000

# Snapshot every nth iteration in the specified directory
snapshot: 100000
snapshot_prefix: "snapshots/"

random_seed: 1701
# Display the loss averaged over the last average_loss iterations - this does not work for accuracy
average_loss: 100
#clip_gradients: 10

# GPU for the win!
solver_mode: GPU
